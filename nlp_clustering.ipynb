{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "16vc6i55_2nL3JYF-dW00mCj3h90PiI7d",
      "authorship_tag": "ABX9TyPBHa/KKKKbX4r3Og3oF46V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AN-Akhand/Transaction-Data-Clustering-with-NLP/blob/main/nlp_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel"
      ],
      "metadata": {
        "id": "7ek8TGm_n7po"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "Wh718QG8pCSb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Transaction_Naration_Data_Set.csv\")"
      ],
      "metadata": {
        "id": "aYZpTrHgDGoi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.display.max_colwidth = 100"
      ],
      "metadata": {
        "id": "hf8Eo1ys6ms_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['NARATION'].iloc[[21886]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhHGoH9sZbDA",
        "outputId": "b63544d2-aeac-460f-9cb9-6a4721f09a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21886    CAP (Smart App), NPSB Fund Transfer. Trf to ,SOCIAL ISLAMI BANK LTD fr BA\n",
              "Name: NARATION, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(15)"
      ],
      "metadata": {
        "id": "kGDclRI6rQIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('words')\n",
        "valid_words = set(nltk.corpus.words.words())\n",
        "stopwords = stopwords.words('english')\n",
        "stopwords.extend(['no', 'c', 'ae', 'st', 'palli', 'b', 'beauty', 'bazaar', 'id',\n",
        "                  'hat', 'x', 'l', 'bu', 'roll', 'amount', 'bill', 'branch',\n",
        "                  'salary', 'amt', 'account', 'bank', 'office', 'al', 'mamum', \n",
        "                  'hasan', 'hossain', 'mar', 'amt', 'islami', 'sonali', 'nid', \n",
        "                  'itna', 'govt', 'usd', 'miah', 'uddin', 'eid', 'ul', 'fitr', \n",
        "                  'ac', 'title', 'begum', 'para', 'title', 'shahin', 'per', \n",
        "                  'month', 'k', 'khan'])\n",
        "x = []\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "def lemmatize_text(text):\n",
        "  return [lemmatizer.lemmatize(w, 'v') for w in w_tokenizer.tokenize(text)]"
      ],
      "metadata": {
        "id": "E76xvYjnPQFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5035980-db21-499d-b793-68d07b015726"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nar = pd.DataFrame(data.loc[:, 'NARATION'])\n",
        "nar = nar.drop_duplicates()"
      ],
      "metadata": {
        "id": "7wGwQ2rZWfB-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nar.loc[:,'NARATION']=nar['NARATION'].str.lower()\n",
        "nar.loc[:,'NARATION'] = nar.loc[:,'NARATION'].str.replace('withdrawal', 'withdraw')\n",
        "nar.loc[:,'NARATION'] = nar['NARATION'].str.replace('[^A-Za-z]+', ' ', regex=True)\n",
        "nar = nar.replace(['^\\s+$'], np.nan, regex = True)\n",
        "nar = nar[nar['NARATION'].notnull()]\n",
        "nar.loc[:,'NARATION'] = nar.loc[:,'NARATION'].apply(lambda words: ' '.join(word.lower() for word in words.split(' ') if word not in stopwords))\n",
        "nar.loc[:,'NARATION'] = nar.loc[:,'NARATION'].apply(lambda words: ' '.join(word.lower() for word in words.split(' ') if word in valid_words))\n",
        "nar.loc[:,'lem_tok'] = nar.loc[:,'NARATION'].apply(lemmatize_text)\n",
        "nar = nar[nar['lem_tok'].map(lambda d: len(d)) > 0]"
      ],
      "metadata": {
        "id": "uv42qFoNaMjt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nar = nar.drop_duplicates(subset=['NARATION'])"
      ],
      "metadata": {
        "id": "ZApTbTiohYVa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nar"
      ],
      "metadata": {
        "id": "tvX3dRMkp1l-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = nar.sample(1000, random_state=1234)"
      ],
      "metadata": {
        "id": "-GzC3jjyV-dm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):  \n",
        "  id2word = corpora.Dictionary(test['lem_tok'])\n",
        "  texts = test['lem_tok']\n",
        "  corpus = [id2word.doc2bow(text) for text in texts]\n",
        "  [[(id2word[id], freq) for id, freq in cp] for cp in corpus]\n",
        "  lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                             id2word=id2word,\n",
        "                                             num_topics=i + 1, \n",
        "                                             random_state=100,\n",
        "                                             update_every=1,\n",
        "                                             chunksize=100,\n",
        "                                             passes=8,\n",
        "                                             alpha='auto',\n",
        "                                             per_word_topics=True)\n",
        "  doc_lda = lda_model[corpus]\n",
        "  coherence_model_lda = CoherenceModel(model=lda_model, texts=test['lem_tok'], dictionary=id2word, coherence='c_v')\n",
        "  coherence_lda = coherence_model_lda.get_coherence()\n",
        "  print('\\nNo of clusters: ', i + 1)\n",
        "  print('\\nCoherence Score: ', coherence_lda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDADQ_GhoH4w",
        "outputId": "14385bd6-3f2c-49d3-ec2d-48b5308b8e73"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "No of clusters:  1\n",
            "\n",
            "Coherence Score:  0.3840496668825152\n",
            "\n",
            "No of clusters:  2\n",
            "\n",
            "Coherence Score:  0.49313866081938\n",
            "\n",
            "No of clusters:  3\n",
            "\n",
            "Coherence Score:  0.5337162922194788\n",
            "\n",
            "No of clusters:  4\n",
            "\n",
            "Coherence Score:  0.6025630924708253\n",
            "\n",
            "No of clusters:  5\n",
            "\n",
            "Coherence Score:  0.6314968909280414\n",
            "\n",
            "No of clusters:  6\n",
            "\n",
            "Coherence Score:  0.5853152138079539\n",
            "\n",
            "No of clusters:  7\n",
            "\n",
            "Coherence Score:  0.615862637540845\n",
            "\n",
            "No of clusters:  8\n",
            "\n",
            "Coherence Score:  0.6177622767947615\n",
            "\n",
            "No of clusters:  9\n",
            "\n",
            "Coherence Score:  0.6220134339484906\n",
            "\n",
            "No of clusters:  10\n",
            "\n",
            "Coherence Score:  0.6080859768088855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=5, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=8,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)\n",
        "pprint(lda_model.print_topics())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjaNMndn6ogV",
        "outputId": "76d07277-7b7d-467f-efda-a44724bb374e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0,\n",
            "  '0.060*\"loan\" + 0.054*\"fee\" + 0.047*\"disbursement\" + 0.038*\"transaction\" + '\n",
            "  '0.022*\"allowance\" + 0.020*\"charge\" + 0.019*\"wrongly\" + 0.017*\"outlet\" + '\n",
            "  '0.014*\"monthly\" + 0.013*\"rectification\"'),\n",
            " (1,\n",
            "  '0.143*\"transfer\" + 0.139*\"fund\" + 0.094*\"smart\" + 0.059*\"regular\" + '\n",
            "  '0.050*\"cap\" + 0.030*\"payment\" + 0.020*\"doc\" + 0.016*\"march\" + 0.015*\"rent\" '\n",
            "  '+ 0.013*\"transaction\"'),\n",
            " (2,\n",
            "  '0.039*\"sod\" + 0.027*\"das\" + 0.027*\"post\" + 0.027*\"abu\" + 0.021*\"need\" + '\n",
            "  '0.019*\"amin\" + 0.018*\"time\" + 0.016*\"cost\" + 0.015*\"support\" + 0.013*\"tax\"'),\n",
            " (3,\n",
            "  '0.110*\"credit\" + 0.050*\"cheque\" + 0.047*\"bank\" + 0.039*\"agent\" + '\n",
            "  '0.018*\"limit\" + 0.017*\"ad\" + 0.015*\"road\" + 0.015*\"client\" + 0.014*\"gram\" + '\n",
            "  '0.013*\"purchase\"'),\n",
            " (4,\n",
            "  '0.174*\"cash\" + 0.123*\"deposit\" + 0.115*\"withdraw\" + 0.060*\"agent\" + '\n",
            "  '0.050*\"inter\" + 0.025*\"purpose\" + 0.014*\"n\" + 0.013*\"due\" + 0.013*\"name\" + '\n",
            "  '0.010*\"return\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nar.to_csv(\"/content/drive/MyDrive/Pre_Processed_Transaction_Naration_Data_Set.csv\")"
      ],
      "metadata": {
        "id": "CKq-6XTdgsrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = data.sample(5000, random_state=123)\n",
        "sample.loc[:,'NARATION']=sample['NARATION'].str.lower()\n",
        "sample.loc[:,'NARATION'] = sample.loc[:,'NARATION'].str.replace('withdrawal', 'withdraw')\n",
        "sample.loc[:,'NARATION'] = sample.loc[:,'NARATION'].str.replace('[^A-Za-z0-9]+', ' ', regex=True)\n",
        "sample.loc[:,'NARATION'] = sample.loc[:,'NARATION'].apply(lambda words: ' '.join(word.lower() for word in words.split(' ') if word not in stopwords))\n",
        "sample.loc[:,'lemmatized_tokens'] = sample.loc[:,'NARATION'].apply(lemmatize_text)"
      ],
      "metadata": {
        "id": "omw0HDoGDVUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample.head(50)"
      ],
      "metadata": {
        "id": "91-lZbacO3A2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}